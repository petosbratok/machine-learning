# -*- coding: utf-8 -*-
"""House prices predictor 2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uw_spCGtRa3bxRWhvqe6qZY7gYpGHz3w
"""

import pandas as pd
import numpy as np

# Make numpy values easier to read.
np.set_printoptions(precision=3, suppress=True)

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras import regularizers
#from sklearn import preprocessing
from sklearn.model_selection import train_test_split

housePrices=pd.read_csv('train.csv')

housePrices.head()

housePrices['GarageYrBlt'].fillna(housePrices['GarageYrBlt'].mean(), inplace=True)

housePrices['MasVnrType'].value_counts()

housePrices[housePrices['MasVnrArea'] == 0]

housePrices.info()

housePrices['LotFrontage'].fillna(int(housePrices['LotFrontage'].mean()), inplace=True) # Space between street and home
housePrices['Utilities'].fillna('AllPub', inplace=True) # 1459 AllPub
housePrices['MSZoning'].fillna('RL', inplace=True) # Not needed
housePrices['Exterior1st'].fillna('VinylSd', inplace=True) # Not needed
housePrices['Exterior2nd'].fillna('VinylSd', inplace=True) # Not needed
housePrices['Electrical'].fillna('SBrkr', inplace=True) # 1459 SBrkr
housePrices['KitchenQual'].fillna('GD', inplace=True) # GD is the 2nd most popular (good)
housePrices['Functional'].fillna('Typ', inplace=True) # 1360 Typ

housePrices['MasVnrArea'].fillna(0, inplace=True)

housePrices['Alley'].fillna('None', inplace=True) # No alley

housePrices['BsmtQual'].fillna('None', inplace=True) # No basement
housePrices['BsmtCond'].fillna('None', inplace=True)
housePrices['BsmtExposure'].fillna('None', inplace=True)
housePrices['BsmtFinType2'].fillna('None', inplace=True)
housePrices['BsmtFinType1'].fillna('None', inplace=True)

housePrices['GarageType'].fillna('None', inplace=True) # No garage
housePrices['GarageQual'].fillna('None', inplace=True) 
housePrices['GarageFinish'].fillna('None', inplace=True) 
housePrices['GarageCond'].fillna('None', inplace=True) 
housePrices['GarageYrBlt'].fillna(housePrices['GarageYrBlt'].mean(), inplace=True) # Gotta fill it with something

housePrices['PoolQC'].fillna('None', inplace=True) # No pool
housePrices['Fence'].fillna('None', inplace=True) # No fence
housePrices['MasVnrType'].fillna('None', inplace=True) # No veneer
housePrices['FireplaceQu'].fillna('None', inplace=True) # No fireplace
housePrices['MiscFeature'].fillna('None', inplace=True) # No feature

housePrices['MSSubClass'] = housePrices['MSSubClass'].astype(str)

housePrices.dtypes

train, test = train_test_split(housePrices, test_size=0.2)
train, val = train_test_split(train, test_size=0.2)
print(len(train), 'train examples')
print(len(val), 'validation examples')
print(len(test), 'test examples')

housePrices_features = train.copy()
housePrices_labels = housePrices_features.pop('SalePrice')
housePrices_labels = housePrices_labels/150000

val_features = val.copy()
val_labels = val.pop('SalePrice')
val_labels = val_labels/150000

print(housePrices_features.dtypes)
print(housePrices_labels.dtypes)

inputs = {}

for name, column in housePrices_features.items():
  dtype = column.dtype
  if dtype == object:
    dtype = tf.string
  else:
    dtype = tf.float32

  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)

inputs

numeric_inputs = {name:input for name,input in inputs.items()
                  if input.dtype==tf.float32}

x = layers.Concatenate()(list(numeric_inputs.values()))
norm = preprocessing.Normalization()
norm.adapt(np.array(housePrices[numeric_inputs.keys()]))
all_numeric_inputs = norm(x)

all_numeric_inputs

preprocessed_inputs = [all_numeric_inputs]

for name, input in inputs.items():
  if input.dtype == tf.float32:
    continue
  
  lookup = preprocessing.StringLookup(vocabulary=np.unique(housePrices_features[name]))
  one_hot = preprocessing.CategoryEncoding(max_tokens=lookup.vocab_size())

  x = lookup(input)
  x = one_hot(x)
  preprocessed_inputs.append(x)

preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)

housePrices_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)

# tf.keras.utils.plot_model(model = housePrices_preprocessing , rankdir="LR", dpi=72, show_shapes=True)

housePrices_features_dict = {name: np.array(value) 
                         for name, value in housePrices_features.items()}

features_dict = {name:values[:1] for name, values in housePrices_features_dict.items()}
housePrices_preprocessing(features_dict)

def housePrices_model(preprocessing_head, inputs):
  body = tf.keras.Sequential([
    layers.Dense(24,activation='sigmoid', kernel_regularizer=regularizers.l2(0.001)),
    layers.Dense(4,activation='sigmoid', kernel_regularizer=regularizers.l2(0.001)),
    # layers.Dense(4,activation='relu'),
    layers.Dense(1)
  ])

  preprocessed_inputs = preprocessing_head(inputs)
  result = body(preprocessed_inputs)
  model = tf.keras.Model(inputs, result)

  model.compile(loss='mse', optimizer='adam', metrics=['mae'])
  return model

housePrices_model = housePrices_model(housePrices_preprocessing, inputs)

val_features_dict = {name: np.array(value) 
                         for name, value in val.items()}
history_1 = housePrices_model.fit(x=housePrices_features_dict, y=housePrices_labels,epochs=350,
                        validation_data=(val_features_dict, val_labels))

# Draw a graph of the loss, which is the distance between
# the predicted and actual values during training and validation.
import matplotlib.pyplot as plt
train_loss = history_1.history['mae']
val_loss = history_1.history['mae']
epochs = range(1, len(train_loss) + 1)

plt.plot(epochs, train_loss, 'g.', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Exclude the first few epochs so the graph is easier to read
SKIP = 20

plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')
plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

test = pd.read_csv('test.csv')

test2 = pd.read_csv('test.csv')

test['BsmtFinSF1'].value_counts()

test.info()

test['SaleType'].fillna('WD', inplace=True)
test['LotFrontage'].fillna(int(test['LotFrontage'].mean()), inplace=True) # Space between street and home
test['Utilities'].fillna('AllPub', inplace=True) # 1459 AllPub
test['MSZoning'].fillna('RL', inplace=True) # Not needed
test['Exterior1st'].fillna('VinylSd', inplace=True) # Not needed
test['Exterior2nd'].fillna('VinylSd', inplace=True) # Not needed
test['Electrical'].fillna('SBrkr', inplace=True) # 1459 SBrkr
test['KitchenQual'].fillna('GD', inplace=True) # GD is the 2nd most popular (good)
test['Functional'].fillna('Typ', inplace=True) # 1360 Typ

test['MasVnrArea'].fillna(0, inplace=True)

test['Alley'].fillna('None', inplace=True) # No alley

test['BsmtQual'].fillna('None', inplace=True) # No basement
test['BsmtCond'].fillna('None', inplace=True)
test['BsmtExposure'].fillna('None', inplace=True)
test['BsmtFinType2'].fillna('None', inplace=True)
test['BsmtFinType1'].fillna('None', inplace=True)

test['GarageType'].fillna('None', inplace=True) # No garage
test['GarageQual'].fillna('None', inplace=True)
test['GarageFinish'].fillna('None', inplace=True)
test['GarageCond'].fillna('None', inplace=True)
test['GarageYrBlt'].fillna(test['GarageYrBlt'].mean(), inplace=True) # Gotta fill it with something

test['PoolQC'].fillna('None', inplace=True) # No pool
test['Fence'].fillna('None', inplace=True) # No fence
test['MasVnrType'].fillna('None', inplace=True) # No veneer
test['FireplaceQu'].fillna('None', inplace=True) # No fireplace
test['MiscFeature'].fillna('None', inplace=True) # No feature

test['MSSubClass'] = test['MSSubClass'].astype(str)

test['GarageCars'].fillna(0, inplace=True)
test['GarageArea'].fillna(0, inplace=True)
test['BsmtHalfBath'].fillna(0, inplace=True)
test['BsmtFullBath'].fillna(0, inplace=True)
test['BsmtFinSF1'].fillna(0, inplace=True)

def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  labels = dataframe.pop('SalePrice')
  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  return ds

actuals_available = True
if 'SalePrice' not in list(test.columns):
    test['SalePrice'] = 0 #any value - we will drop
    actuals_available = False

test_ds = df_to_dataset(test, shuffle=False, batch_size=len(test))

ans = housePrices_model.predict(test_ds)

print(ans)

len(ans)

ans.shape()

ans = housePrices_model.predict(test_ds)
ans *= 150000
final_data = pd.DataFrame(data={'SalePrice': [num[0] for num in list(ans)]})
final_data['Id'] = test['Id']
final_data['SalePrice'].fillna(final_data['SalePrice'].mean(), inplace=True)
final_data[['Id', 'SalePrice']].to_csv('submission.csv', index=False)

ans.shape

final_data = pd.DataFrame(data={'SalePrice': [num[0] for num in list(ans)]})

final_data['Id'] = test2['Id']

final_data.head()

final_data['SalePrice'].fillna(final_data['SalePrice'].mean(), inplace=True)

final_data[['Id', 'SalePrice']].to_csv('submission.csv', index=False)

final_data.info()